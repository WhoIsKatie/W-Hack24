{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84c08d9940784fb8b5640c033f17f85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b0ef40ba7934c6c8e1bc381eda6b7ce",
              "IPY_MODEL_4370b02b6c624699a343da1f38774ac1",
              "IPY_MODEL_f1da415b675946e38e4e9d2f7122fe53"
            ],
            "layout": "IPY_MODEL_e0b22a9ca1f54d0ca3f0326cf85f101e"
          }
        },
        "4b0ef40ba7934c6c8e1bc381eda6b7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3447af7f58104f09b238dea387a61b4d",
            "placeholder": "​",
            "style": "IPY_MODEL_ec3356ef8a7a4b34ac61bffdc8c19691",
            "value": "Map: 100%"
          }
        },
        "4370b02b6c624699a343da1f38774ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf978e753634b0ca6a21dcf86f379d3",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26cf5941df4349a394b7447a7be426af",
            "value": 10000
          }
        },
        "f1da415b675946e38e4e9d2f7122fe53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7461a4413fe42b38d9e1ed4a497f844",
            "placeholder": "​",
            "style": "IPY_MODEL_d9a0efc8efdc47f7b1addd6c818888e3",
            "value": " 10000/10000 [00:00&lt;00:00, 64529.30 examples/s]"
          }
        },
        "e0b22a9ca1f54d0ca3f0326cf85f101e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3447af7f58104f09b238dea387a61b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3356ef8a7a4b34ac61bffdc8c19691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf978e753634b0ca6a21dcf86f379d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26cf5941df4349a394b7447a7be426af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7461a4413fe42b38d9e1ed4a497f844": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a0efc8efdc47f7b1addd6c818888e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0532af7a55e84f9b9817d9159380d392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_063e642b84774db7a9d9be781bfe1895",
              "IPY_MODEL_075de5e50a0448c09557a3f37d9aacb7",
              "IPY_MODEL_65d6357454f14a578a2752f6eaffe7ac"
            ],
            "layout": "IPY_MODEL_1419c054a73b4761b17715c9c4e26872"
          }
        },
        "063e642b84774db7a9d9be781bfe1895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40330d53a0354bcaa9a95da17ba090e5",
            "placeholder": "​",
            "style": "IPY_MODEL_2850ae10c56842bfbcd8d1e04874f7c7",
            "value": "Generating train split: "
          }
        },
        "075de5e50a0448c09557a3f37d9aacb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dc98707dc0548078a33d47c4bf18d90",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd8ed4fd0a5d41fb9e270ab6a9f42f99",
            "value": 1
          }
        },
        "65d6357454f14a578a2752f6eaffe7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcf5b469cbb54256921d332d0616eb26",
            "placeholder": "​",
            "style": "IPY_MODEL_22733553da494909a20ff9bda7ea8baa",
            "value": " 3010/0 [00:06&lt;00:00, 704.81 examples/s]"
          }
        },
        "1419c054a73b4761b17715c9c4e26872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40330d53a0354bcaa9a95da17ba090e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2850ae10c56842bfbcd8d1e04874f7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dc98707dc0548078a33d47c4bf18d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "fd8ed4fd0a5d41fb9e270ab6a9f42f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcf5b469cbb54256921d332d0616eb26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22733553da494909a20ff9bda7ea8baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19a1a5785f6740daa49c8366b7c85f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4923b43937f547e88fbaf3bf65c7df5e",
              "IPY_MODEL_89c6fadd6eb94fe2ae49957de05912e3",
              "IPY_MODEL_662f621cfd024137821d4fc748e2e616"
            ],
            "layout": "IPY_MODEL_21c9c2049c71443489ef5e133bb0eb6d"
          }
        },
        "4923b43937f547e88fbaf3bf65c7df5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722b97cb499944d986dd279fa8c3defb",
            "placeholder": "​",
            "style": "IPY_MODEL_8622870610a0455aa9dc10723b329620",
            "value": "Generating train split: "
          }
        },
        "89c6fadd6eb94fe2ae49957de05912e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3e96ed185c4f22b60d962674cbbd39",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7269af50ab040b992f8cdfb23c5d3be",
            "value": 1
          }
        },
        "662f621cfd024137821d4fc748e2e616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f3d0793e63f453f8f312bad7b31b6bf",
            "placeholder": "​",
            "style": "IPY_MODEL_3b432b715130493cbc5eec7746060e4d",
            "value": " 27/0 [00:00&lt;00:00, 291.68 examples/s]"
          }
        },
        "21c9c2049c71443489ef5e133bb0eb6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "722b97cb499944d986dd279fa8c3defb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8622870610a0455aa9dc10723b329620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3e96ed185c4f22b60d962674cbbd39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f7269af50ab040b992f8cdfb23c5d3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f3d0793e63f453f8f312bad7b31b6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b432b715130493cbc5eec7746060e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37f8dc5bded449cf80df93432597d5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51eed054049641749d17b8d92af45ff9",
              "IPY_MODEL_c699d95dad0844d8900b0f02b43ac067"
            ],
            "layout": "IPY_MODEL_22290aac1af0406f9235dcf5ac6d0217"
          }
        },
        "51eed054049641749d17b8d92af45ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3566560c4124eccb85afd05ff76be29",
            "placeholder": "​",
            "style": "IPY_MODEL_6f8840d7ed014ce08d3749ce57c665da",
            "value": "1.736 MB of 1.736 MB uploaded\r"
          }
        },
        "c699d95dad0844d8900b0f02b43ac067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b66253f1d54d1eaff4fb5822048fa4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6960de06a8b749c7a4f8bb73b867c69d",
            "value": 1
          }
        },
        "22290aac1af0406f9235dcf5ac6d0217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3566560c4124eccb85afd05ff76be29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8840d7ed014ce08d3749ce57c665da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b66253f1d54d1eaff4fb5822048fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6960de06a8b749c7a4f8bb73b867c69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "wLswaJOwmlKJ",
        "outputId": "622ff20b-b2db-4d9b-a898-fb6cd96ab7e1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (<ipython-input-23-ea160fedd2c0>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-ea160fedd2c0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://www.analyticsvidhya.com/blog/2024/02/fine-tuning-a-tiny-llama-model-with-unsloth/\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
          ]
        }
      ],
      "source": [
        "https://www.analyticsvidhya.com/blog/2024/02/fine-tuning-a-tiny-llama-model-with-unsloth/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "!pip install wandb\n",
        "if major_version >= 8:\n",
        "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
        "    !pip install \"unsloth[colab_ampere] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "else:\n",
        "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
        "    !pip install \"unsloth[colab] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "pass"
      ],
      "metadata": {
        "id": "asWJGgYJv7fc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/tinyllama-bnb-4bit\", # \"unsloth/tinyllama\" for 16bit loading\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsQXYwALxPFF",
        "outputId": "0100dd5e-c70f-4ac2-8de3-dfe7db2ee4d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"unsloth/tinyllama-bnb-4bit\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 5632,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 22,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.38.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Fast Llama patching release 2024.2\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.1.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. Xformers = 0.0.22.post7. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"unsloth/tinyllama-bnb-4bit\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 5632,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 22,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.38.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"unsloth/tinyllama-bnb-4bit\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 5632,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 22,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.38.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:155: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/model.safetensors\n",
            "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n",
            "target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n",
            "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "All the weights of LlamaForCausalLM were initialized from the model checkpoint at unsloth/tinyllama-bnb-4bit.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_length\": 2048,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n",
            "loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/tokenizer.model\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0, # Currently only supports dropout = 0\n",
        "    bias = \"none\",    # Currently only supports bias = \"none\"\n",
        "    use_gradient_checkpointing = True, # @@@ IF YOU GET OUT OF MEMORY - set to True @@@\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "id": "hDFythVXzi0D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yS2JzNiuzlUf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGNu_Anj2puE",
        "outputId": "80b5e357-ce3d-4a17-c29f-426b7bc8af92"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "DATA_PATH = \"/content/drive/My Drive\"\n",
        "infile = open(DATA_PATH+'/combined_df.pkl','rb')\n",
        "df = pickle.load(infile)"
      ],
      "metadata": {
        "id": "-GTL61ekY2f_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'Email Text': 'input', 'Email Type': 'output'})\n",
        "df"
      ],
      "metadata": {
        "id": "2pUimH1N5fyp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "0163b133-32bd-4e44-fe2e-e6dccb35f74c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   input           output\n",
              "0      re : 6 . 1100 , disc : uniformitarianism , re ...       Safe Email\n",
              "1      the other side of * galicismos * * galicismo *...       Safe Email\n",
              "2      re : equistar deal tickets are you still avail...       Safe Email\n",
              "3      \\nHello I am your hot lil horny toy.\\n    I am...  Malicious Email\n",
              "4      software at incredibly low prices ( 86 % lower...  Malicious Email\n",
              "...                                                  ...              ...\n",
              "23816  Subject: put the 10 on the ft\\r\\nthe transport...       Safe Email\n",
              "23817  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...       Safe Email\n",
              "23818  Subject: calpine daily gas nomination\\r\\n>\\r\\n...       Safe Email\n",
              "23819  Subject: industrial worksheets for august 2000...       Safe Email\n",
              "23820  Subject: important online banking alert\\r\\ndea...  Malicious Email\n",
              "\n",
              "[23821 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-324bbb82-1a10-4115-8928-8d4168210cc7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the other side of * galicismos * * galicismo *...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>re : equistar deal tickets are you still avail...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
              "      <td>Malicious Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
              "      <td>Malicious Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23816</th>\n",
              "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23817</th>\n",
              "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23818</th>\n",
              "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23819</th>\n",
              "      <td>Subject: industrial worksheets for august 2000...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23820</th>\n",
              "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
              "      <td>Malicious Email</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23821 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-324bbb82-1a10-4115-8928-8d4168210cc7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-324bbb82-1a10-4115-8928-8d4168210cc7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-324bbb82-1a10-4115-8928-8d4168210cc7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1cd57aa-d7eb-4f7e-8477-94b99e0af405\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1cd57aa-d7eb-4f7e-8477-94b99e0af405')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1cd57aa-d7eb-4f7e-8477-94b99e0af405 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0b485d5b-6a44-46b9-b04d-0807947ceb9e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0b485d5b-6a44-46b9-b04d-0807947ceb9e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 23821,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22530,\n        \"samples\": [\n          \"Subject: re : ect - im waha ? ? ?\\r\\nall except for last one rollled due to evergreen . when you convert to ena -\\r\\nim texas - don ' t forget to remove the evergreen flag on the old ect - im waha\\r\\ndeals .\\r\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by thomas engel / hou / ect on 08 / 29 / 2000 07 : 24\\r\\nam - - - - - - - - - - - - - - - - - - - - - - - - - - -\\r\\ndaren j farmer\\r\\n08 / 22 / 2000 12 : 45 pm\\r\\nto : thomas engel / hou / ect @ ect\\r\\ncc :\\r\\nsubject : re : ect - im waha ? ? ?\\r\\nthese deals should be converted to ena - im texas . is there a way that you can\\r\\nchange all of these deals systematically ?\\r\\nd\\r\\nfrom : thomas engel 08 / 22 / 2000 08 : 54 am\\r\\nto : daren j farmer / hou / ect @ ect , heidi withers / hou / ees @ ees , trisha\\r\\nhughes / hou / ect @ ect\\r\\ncc : rita wynne / hou / ect @ ect , russ severson / hou / ect @ ect , scott\\r\\nmills / hou / ect @ ect , regina perkins / hou / ect @ ect\\r\\nsubject : ect - im waha ? ? ?\\r\\nshould these not be converted to ena - im texas ? ? ? some time ago - we were\\r\\ntold this desk was dead and the existing deals would end . this desk is not\\r\\nincluded in any texas desk portfolios .\\r\\nthe ect desks are supposed to be inactive - however - these deals keep\\r\\nrolling - and\\r\\nsomeone created some new ones ? if the desk is active - should we change it\\r\\nto ena - im waha -\\r\\nas ect is no more ? ? ?\",\n          \"re : trademarks for newco i am not sure . detmering has the latest draft and i think discussions are still going on big focus is transition greg piper\",\n          \"FROM: COL. MICHAEL BUNDU. \\nDEMOCRATIC REPUBLIC OF CONGO. \\nTel No: Your country Intl. access code +8821652098236\\nemail : mikebundu@rediffmail.com\\nDear Sir/Madam\\nSEEKING YOUR IMMEDIATE ASSISTANCE. Please permit me to make your acquaintance in so informal a manner. This\\nis necessitated by my urgent need to reach a \\ndependable and trust worthy foreign partner. This request may seem strange\\nand unsolicited but I crave your indulgence \\nand pray that you view it seriously. My name is COL. MICHAEL BUNDU of the\\nDemocratic Republic of Congo and one of \\nthe close aides to the former President of the Democratic Republic of\\nCongo LAURENT KABILA of blessed memory, may \\nhis soul rest in peace. Due to the military campaign of LAURENT KABILA to force out the rebels in\\nmy country, I and some of my colleagues were \\ninstructed by Late President Kabila to go abroad to purchase arms and\\nammunition worth of Twenty Million, Five Hundred \\nThousand United States Dollars only (US$20,500,000.00) to fight the rebel\\ngroup. We were then given this money privately \\nby the then President, LAURENT KABILA, without the knowledge of other\\nCabinet Members. But when President Kabila \\nwas killed in a bloody shoot-out by one of his bodyguards a day before we\\nwere schedule to travel out of Congo, We \\nimmediately decided to put the funds into a private security company here\\nin Congo for safe keeping. The security of the \\nsaid amount is presently being threatened here following the arrest and\\nseizure of properties of Col. Rasheidi Karesava \\n(One of the aides to Laurent Kabila) a tribesman, and some other Military\\nPersonnel from our same tribe, by the new \\nPresident of the Democratic Republic of Congo, the son of late President\\nLaurent Kabila, Joseph Kabila. In view of this, we need a reliable and trustworthy foreign partner who\\ncan assist us to move this money out of my country \\nas the beneficiary. \\nWE have sufficient ''CONTACTS'' here to move the fund under Diplomatic\\nCover to a security company in Europe in your \\nname. This is to ensure that the Diplomatic Baggage is marked\\n''CONFIDENTIAL'' and it \\nwill not pass through normal custom/airport screening and clearance. Our inability to move this money out of Congo all this while stems from\\nour lack of trust of our supposed good friends \\n(western countries) who suddenly became hostile to those of us who worked\\nwith the late President Kabila, immediately \\nafter his son took office. Though we have neither seen nor met each other,\\nthe information We gathered from an associate \\nwho has worked in your country has encouraged and convinced us that with\\nyour sincere assistance, this transaction will \\nbe properly handled with modesty and honesty to a huge success within two\\nweeks. The said money is a state fund and \\ntherefore requires a total confidentiality. We would please need you to stand on our behalf as the beneficiary of this\\nfund in Europe. This is because we are under \\nrestricted movement and watch and hence we want to be very careful in\\norder not to lose this fund which we have worked \\nso hard for. Thus, if you are willing to assist us to move this fund out\\nof Congo, you can contact me through my email \\naddresses, Tel/Fax nos. above with your telephone, fax number and personal\\ninformation to enable us discuss the \\nmodalities and what will be your share (percentage) for assisting us.Please note that There are no RISKS involved in this Deal as everyone's\\nSecurity is Guaranteed if we follow the required \\nguidelines. I will hence furnish you with further details of this Deal as\\nsoon as I am assured of your Sincere interest to assist \\nus. I must use this opportunity and medium to implore you to exercise the\\nutmost indulgence to keep this matter extraordinarily \\nconfidential, Whatever your decision, while I await your prompt response.\\nThank you and God Bless. \\nBest Regards \\nCOL. MICHAEL BUNDU(RTD). m_bundu@rediffmail.comN\\\\B. When you are calling my line, you dial your country Intl. access\\ncode, then you dial directly, do not include my country \\ncode i.e. (243). Just dial your country Intl. access code + 88216\\n52098236. You can also contact me through the above \\nemail addresses.-- \\nIrish Linux Users' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Malicious Email\",\n          \"Safe Email\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df['output'].value_counts()"
      ],
      "metadata": {
        "id": "2M75iJczDKFB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Fgzfs_EOcV",
        "outputId": "6cee9221-b985-4be0-a578-ae0ab9053876"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Safe Email         14994\n",
              "Malicious Email     8827\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_df = df.sample(n=10000, random_state=3407)"
      ],
      "metadata": {
        "id": "CoIHDegrEbyv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "tUMuSFxeFLng",
        "outputId": "71c15263-080e-4ec4-9c08-babf032a3273"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   input           output\n",
              "6853   re : lloyd , i think that we can arrange a few...       Safe Email\n",
              "9872   WE NEED HELP.  We are a 14 year old fortune 50...  Malicious Email\n",
              "15377  slipped ambl 1 en , xanaax , tussioneex , \\ / ...  Malicious Email\n",
              "10540  The pay's not good (9,300 a year), but there i...       Safe Email\n",
              "9718   vacation scheduled i will be on vacation frida...       Safe Email\n",
              "...                                                  ...              ...\n",
              "16575  = ? utf - 8 ? q ? you might become to ? = = ? ...  Malicious Email\n",
              "15772  honored by two keynote speakers international ...       Safe Email\n",
              "14573  exactseek - verify your site submission the fo...  Malicious Email\n",
              "17171  enron capitalism a primer on how to succeed in...       Safe Email\n",
              "414    On Fri, 6 Sep 2002, Russell Turpin wrote:> You...       Safe Email\n",
              "\n",
              "[10000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7538897-630c-46ec-9185-4a816b918255\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6853</th>\n",
              "      <td>re : lloyd , i think that we can arrange a few...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9872</th>\n",
              "      <td>WE NEED HELP.  We are a 14 year old fortune 50...</td>\n",
              "      <td>Malicious Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15377</th>\n",
              "      <td>slipped ambl 1 en , xanaax , tussioneex , \\ / ...</td>\n",
              "      <td>Malicious Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10540</th>\n",
              "      <td>The pay's not good (9,300 a year), but there i...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9718</th>\n",
              "      <td>vacation scheduled i will be on vacation frida...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16575</th>\n",
              "      <td>= ? utf - 8 ? q ? you might become to ? = = ? ...</td>\n",
              "      <td>Malicious Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15772</th>\n",
              "      <td>honored by two keynote speakers international ...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14573</th>\n",
              "      <td>exactseek - verify your site submission the fo...</td>\n",
              "      <td>Malicious Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17171</th>\n",
              "      <td>enron capitalism a primer on how to succeed in...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>On Fri, 6 Sep 2002, Russell Turpin wrote:&gt; You...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7538897-630c-46ec-9185-4a816b918255')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7538897-630c-46ec-9185-4a816b918255 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7538897-630c-46ec-9185-4a816b918255');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d998526c-cc8f-4442-9248-8ed97bb2f347\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d998526c-cc8f-4442-9248-8ed97bb2f347')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d998526c-cc8f-4442-9248-8ed97bb2f347 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d993ba90-670f-492e-901e-106fe9fb04a1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('trimmed_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d993ba90-670f-492e-901e-106fe9fb04a1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('trimmed_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "trimmed_df",
              "summary": "{\n  \"name\": \"trimmed_df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9657,\n        \"samples\": [\n          \"quickie one morning dick cheney and george w . bush were having brunch at a restaurant . the attractive waitress asks cheney what he would like and he replies , \\\" i ' ll have a bowl of oatmeal and some fruit . \\\" \\\" and what can i get for you , sir ? \\\" she asks george w . he replies , \\\" how about a quickie ? \\\" \\\" why , mr . president , \\\" the waitress says , \\\" how rude . . . you ' re starting to act like mr . clinton and you haven ' t even been in office for a month yet ! \\\" as the waitress storms away , cheney leans over to bush and whispers , \\\" it ' s pronounced \\\" quiche . \\\"\",\n          \"enron europe office summary - august 2000 please find attached the august summary of enron europe ' s remote offices . this has now been updated to include enron metals locations , but has not been updated for recent announcements concerning japan and australia . please could you let me know if there are any changes that need to be made and if anyone else should be included on the distribution list . best regards , lisa fair european financial operations administrator ext : 37123 ddi : + 44 ( 0 ) 20 7783 7123 fax : + 44 ( 0 ) 20 7783 8291\",\n          \"now , it ' s finally possible for you to enlarge your penis good news men ! all your problems with small penis and poor erections will become history ! ! ! http : / / www . xunepa . com / ss / it is never too late to give up your prejudices . our lives teach us who we are . virtue is indeed its own reward . a good conscience is a continual christmas . america guarantees equal opportunity , not equal outcome .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Malicious Email\",\n          \"Safe Email\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = trimmed_df['output'].value_counts()\n",
        "class_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ghiKIQXFTZt",
        "outputId": "781ad34d-3455-40b7-a774-4875c1a885fe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Safe Email         6268\n",
              "Malicious Email    3732\n",
              "Name: output, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert from df to dataset\n",
        "import datasets\n",
        "dataset = datasets.Dataset.from_pandas(trimmed_df)"
      ],
      "metadata": {
        "id": "QFhrQXBNAkCD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5vxo03SZZxN",
        "outputId": "c3b94c74-f7c4-4a8d-a6bd-043d3c6c1f5e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input', 'output', '__index_level_0__'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title prepare data\n",
        "\n",
        "alpaca_prompt = \"\"\".\n",
        "\n",
        "Given the input email and the reponse determine if the email provided below is safe or potentially malicious based on its\n",
        "content. If the email seems legitimate and does not contain any\n",
        "harmful intent, threats, or suspicious requests, classify it as\n",
        "\"safe\". If the email contains elements typical of phishing attempts,\n",
        "such as requests for sensitive information, suspicious links, or unusual\n",
        "sender addresses, classify it as \"potentially malicious\".\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for input, output in zip(inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "id": "MtJD8Q-LBMa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "84c08d9940784fb8b5640c033f17f85d",
            "4b0ef40ba7934c6c8e1bc381eda6b7ce",
            "4370b02b6c624699a343da1f38774ac1",
            "f1da415b675946e38e4e9d2f7122fe53",
            "e0b22a9ca1f54d0ca3f0326cf85f101e",
            "3447af7f58104f09b238dea387a61b4d",
            "ec3356ef8a7a4b34ac61bffdc8c19691",
            "1bf978e753634b0ca6a21dcf86f379d3",
            "26cf5941df4349a394b7447a7be426af",
            "e7461a4413fe42b38d9e1ed4a497f844",
            "d9a0efc8efdc47f7b1addd6c818888e3"
          ]
        },
        "outputId": "c89940a9-f141-4063-b7cd-98c580da9a2a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84c08d9940784fb8b5640c033f17f85d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]\n",
        "dataset_dict = dataset.train_test_split(test_size=0.01)\n",
        "dataset_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4LC_lHnbhy6",
        "outputId": "2b07f14e-35b6-40c5-99ef-1b45fc4d377b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output', '__index_level_0__', 'text'],\n",
              "        num_rows: 9900\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input', 'output', '__index_level_0__', 'text'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title wandb init\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMbS5kNeMR-9",
        "outputId": "ef378bec-ad8c-4e1e-bb8d-582e118156bb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%env WANDB_WATCH=all\n",
        "%env WANDB_SILENT=true\n",
        "os.environ.get(\"WANDB_SILENT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "OJEbJDUiMaIk",
        "outputId": "42b3bb0a-acb6-4d73-91f1-10cdf4415bd6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_WATCH=all\n",
            "env: WANDB_SILENT=true\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'true'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from transformers.utils import logging\n",
        "import wandb\n",
        "\n",
        "logging.set_verbosity_info()\n",
        "project_name = \"tiny-llama\"\n",
        "entity = \"wandb\"\n",
        "# os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "\n",
        "wandb.init(project=project_name, name = \"run_10000\")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset_dict[\"train\"],\n",
        "    eval_dataset=dataset_dict[\"test\"],\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = True, # Packs short sequences together to save time!\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        per_device_eval_batch_size=2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        warmup_ratio = 0.1,\n",
        "        num_train_epochs = 1,\n",
        "        learning_rate = 2e-5,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.1,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to=\"wandb\",  # enable logging to W&B\n",
        "        # run_name=\"tiny-llama-alpaca-run6\",  # name of the W&B run (optional)\n",
        "        logging_steps=1,  # how often to log to W&B\n",
        "        logging_strategy = 'steps',\n",
        "        save_total_limit=2,\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "0532af7a55e84f9b9817d9159380d392",
            "063e642b84774db7a9d9be781bfe1895",
            "075de5e50a0448c09557a3f37d9aacb7",
            "65d6357454f14a578a2752f6eaffe7ac",
            "1419c054a73b4761b17715c9c4e26872",
            "40330d53a0354bcaa9a95da17ba090e5",
            "2850ae10c56842bfbcd8d1e04874f7c7",
            "2dc98707dc0548078a33d47c4bf18d90",
            "fd8ed4fd0a5d41fb9e270ab6a9f42f99",
            "fcf5b469cbb54256921d332d0616eb26",
            "22733553da494909a20ff9bda7ea8baa",
            "19a1a5785f6740daa49c8366b7c85f9b",
            "4923b43937f547e88fbaf3bf65c7df5e",
            "89c6fadd6eb94fe2ae49957de05912e3",
            "662f621cfd024137821d4fc748e2e616",
            "21c9c2049c71443489ef5e133bb0eb6d",
            "722b97cb499944d986dd279fa8c3defb",
            "8622870610a0455aa9dc10723b329620",
            "4c3e96ed185c4f22b60d962674cbbd39",
            "f7269af50ab040b992f8cdfb23c5d3be",
            "0f3d0793e63f453f8f312bad7b31b6bf",
            "3b432b715130493cbc5eec7746060e4d"
          ]
        },
        "id": "tzLQjxFjMc2F",
        "outputId": "5ba7b9d4-ac45-44eb-ba21-b352f254f009"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240303_013417-0976sk6p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fengdu/tiny-llama/runs/0976sk6p' target=\"_blank\">run_10000</a></strong> to <a href='https://wandb.ai/fengdu/tiny-llama' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/fengdu/tiny-llama' target=\"_blank\">https://wandb.ai/fengdu/tiny-llama</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/fengdu/tiny-llama/runs/0976sk6p' target=\"_blank\">https://wandb.ai/fengdu/tiny-llama/runs/0976sk6p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 1\n",
            "PyTorch: setting up devices\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0532af7a55e84f9b9817d9159380d392"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (8311 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19a1a5785f6740daa49c8366b7c85f9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using auto half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.eval_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mtY7DMoNfoV",
        "outputId": "18229f5a-53c3-4302-e59a-7ffe2264530c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'labels'],\n",
              "    num_rows: 27\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "37f8dc5bded449cf80df93432597d5a9",
            "51eed054049641749d17b8d92af45ff9",
            "c699d95dad0844d8900b0f02b43ac067",
            "22290aac1af0406f9235dcf5ac6d0217",
            "b3566560c4124eccb85afd05ff76be29",
            "6f8840d7ed014ce08d3749ce57c665da",
            "59b66253f1d54d1eaff4fb5822048fa4",
            "6960de06a8b749c7a4f8bb73b867c69d"
          ]
        },
        "id": "PnRKEa4VNiFA",
        "outputId": "2bc78e5f-4ef2-4f8f-dd20-2e89945c7e02"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 3,010 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 376\n",
            " \"-____-\"     Number of trainable parameters = 25,231,360\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [376/376 1:48:29, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.513300</td>\n",
              "      <td>2.456930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.688200</td>\n",
              "      <td>2.456757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.455400</td>\n",
              "      <td>2.456362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.432500</td>\n",
              "      <td>2.455521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.722200</td>\n",
              "      <td>2.454160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.417100</td>\n",
              "      <td>2.452044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.513800</td>\n",
              "      <td>2.449020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.542800</td>\n",
              "      <td>2.444890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.341100</td>\n",
              "      <td>2.439451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.465100</td>\n",
              "      <td>2.432946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.516300</td>\n",
              "      <td>2.425138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.659900</td>\n",
              "      <td>2.415929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.396600</td>\n",
              "      <td>2.405806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.229500</td>\n",
              "      <td>2.394884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.426500</td>\n",
              "      <td>2.382973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.322900</td>\n",
              "      <td>2.370409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>2.332400</td>\n",
              "      <td>2.357966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>2.243500</td>\n",
              "      <td>2.346112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>2.301500</td>\n",
              "      <td>2.334832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.280400</td>\n",
              "      <td>2.324100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>2.480100</td>\n",
              "      <td>2.313197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>2.477000</td>\n",
              "      <td>2.302191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>2.363100</td>\n",
              "      <td>2.290285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>2.442100</td>\n",
              "      <td>2.277976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.200700</td>\n",
              "      <td>2.267437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>2.548700</td>\n",
              "      <td>2.258956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>2.360100</td>\n",
              "      <td>2.252322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>2.732200</td>\n",
              "      <td>2.246439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>2.141100</td>\n",
              "      <td>2.240950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.212400</td>\n",
              "      <td>2.236382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>2.145900</td>\n",
              "      <td>2.231504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>2.279100</td>\n",
              "      <td>2.226872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>2.141000</td>\n",
              "      <td>2.222200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>2.178300</td>\n",
              "      <td>2.217694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>2.313000</td>\n",
              "      <td>2.213488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>2.272300</td>\n",
              "      <td>2.209502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>2.350200</td>\n",
              "      <td>2.205538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>2.730000</td>\n",
              "      <td>2.201617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>2.339800</td>\n",
              "      <td>2.197349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.225800</td>\n",
              "      <td>2.193340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>2.113800</td>\n",
              "      <td>2.189341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>2.185176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>2.131500</td>\n",
              "      <td>2.181099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>2.178300</td>\n",
              "      <td>2.176950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.112000</td>\n",
              "      <td>2.172764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>2.226000</td>\n",
              "      <td>2.168600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>2.138900</td>\n",
              "      <td>2.164452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>2.282800</td>\n",
              "      <td>2.160321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>2.256000</td>\n",
              "      <td>2.156304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.109500</td>\n",
              "      <td>2.152213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>2.079900</td>\n",
              "      <td>2.148287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>2.151300</td>\n",
              "      <td>2.144365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>2.114800</td>\n",
              "      <td>2.140419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>2.102900</td>\n",
              "      <td>2.136430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>2.274800</td>\n",
              "      <td>2.132452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.949700</td>\n",
              "      <td>2.128471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>2.287100</td>\n",
              "      <td>2.124502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>2.371300</td>\n",
              "      <td>2.120596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>2.210400</td>\n",
              "      <td>2.116712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.080400</td>\n",
              "      <td>2.112888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.994900</td>\n",
              "      <td>2.109000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>2.233400</td>\n",
              "      <td>2.105182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>2.149400</td>\n",
              "      <td>2.101362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>2.226000</td>\n",
              "      <td>2.097610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>2.033100</td>\n",
              "      <td>2.093886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>2.254900</td>\n",
              "      <td>2.090148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>2.030600</td>\n",
              "      <td>2.086461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>2.062000</td>\n",
              "      <td>2.082671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>2.083400</td>\n",
              "      <td>2.079031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.907700</td>\n",
              "      <td>2.075411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>2.163500</td>\n",
              "      <td>2.071854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>2.163300</td>\n",
              "      <td>2.068274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>2.288900</td>\n",
              "      <td>2.064698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>2.131300</td>\n",
              "      <td>2.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>2.079600</td>\n",
              "      <td>2.057681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>2.187300</td>\n",
              "      <td>2.054163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>2.117700</td>\n",
              "      <td>2.050693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>2.096200</td>\n",
              "      <td>2.047284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>2.049200</td>\n",
              "      <td>2.043897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.082100</td>\n",
              "      <td>2.040625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>2.554700</td>\n",
              "      <td>2.037213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>2.272500</td>\n",
              "      <td>2.033973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>2.187000</td>\n",
              "      <td>2.030820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>2.009300</td>\n",
              "      <td>2.027690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>2.036500</td>\n",
              "      <td>2.024582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>2.018600</td>\n",
              "      <td>2.021499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.960800</td>\n",
              "      <td>2.018431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>2.046600</td>\n",
              "      <td>2.015442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>2.057800</td>\n",
              "      <td>2.012558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.088400</td>\n",
              "      <td>2.009824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>2.080500</td>\n",
              "      <td>2.007066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>2.111700</td>\n",
              "      <td>2.004211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>2.040100</td>\n",
              "      <td>2.001385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>2.062100</td>\n",
              "      <td>1.998763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>2.031700</td>\n",
              "      <td>1.996181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>2.060800</td>\n",
              "      <td>1.993722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>2.066300</td>\n",
              "      <td>1.991465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>2.023400</td>\n",
              "      <td>1.989230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.888600</td>\n",
              "      <td>1.987066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.845600</td>\n",
              "      <td>1.984968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>2.311600</td>\n",
              "      <td>1.982977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>2.143700</td>\n",
              "      <td>1.981024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>1.846900</td>\n",
              "      <td>1.979138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>1.967200</td>\n",
              "      <td>1.977298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.858400</td>\n",
              "      <td>1.975500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>1.880300</td>\n",
              "      <td>1.973860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>2.076400</td>\n",
              "      <td>1.972366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>2.007400</td>\n",
              "      <td>1.970780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>1.966300</td>\n",
              "      <td>1.969239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>2.139900</td>\n",
              "      <td>1.967691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.982100</td>\n",
              "      <td>1.966255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>2.014400</td>\n",
              "      <td>1.964756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>2.091500</td>\n",
              "      <td>1.963447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>2.073600</td>\n",
              "      <td>1.961967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.910700</td>\n",
              "      <td>1.960635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>1.805200</td>\n",
              "      <td>1.959250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>2.040700</td>\n",
              "      <td>1.957987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>2.199200</td>\n",
              "      <td>1.956746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>1.878200</td>\n",
              "      <td>1.955556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.976200</td>\n",
              "      <td>1.954394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>1.895400</td>\n",
              "      <td>1.953273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>1.946500</td>\n",
              "      <td>1.952111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>2.141900</td>\n",
              "      <td>1.951043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>2.055400</td>\n",
              "      <td>1.949962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>2.141500</td>\n",
              "      <td>1.948807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>1.911700</td>\n",
              "      <td>1.947569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>1.946000</td>\n",
              "      <td>1.946415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>1.818500</td>\n",
              "      <td>1.945233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>1.934600</td>\n",
              "      <td>1.944166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.915400</td>\n",
              "      <td>1.943068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>1.918600</td>\n",
              "      <td>1.941958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>1.873200</td>\n",
              "      <td>1.940889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>1.939200</td>\n",
              "      <td>1.939900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>1.858900</td>\n",
              "      <td>1.938838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.918800</td>\n",
              "      <td>1.937826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>1.914600</td>\n",
              "      <td>1.936769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>2.050100</td>\n",
              "      <td>1.935758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>2.209600</td>\n",
              "      <td>1.934834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>2.033800</td>\n",
              "      <td>1.933901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.814200</td>\n",
              "      <td>1.932917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>1.987000</td>\n",
              "      <td>1.932079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>2.293600</td>\n",
              "      <td>1.931204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>1.842600</td>\n",
              "      <td>1.930324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>2.147300</td>\n",
              "      <td>1.929422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>2.157500</td>\n",
              "      <td>1.928573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>1.865200</td>\n",
              "      <td>1.927734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>1.981300</td>\n",
              "      <td>1.926831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>1.785700</td>\n",
              "      <td>1.925998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>1.908200</td>\n",
              "      <td>1.925173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.054800</td>\n",
              "      <td>1.924399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>2.017900</td>\n",
              "      <td>1.923654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>2.123400</td>\n",
              "      <td>1.922981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>1.988200</td>\n",
              "      <td>1.922224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>1.952000</td>\n",
              "      <td>1.921443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>2.006500</td>\n",
              "      <td>1.920725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>1.983600</td>\n",
              "      <td>1.920070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>1.997700</td>\n",
              "      <td>1.919286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>2.054500</td>\n",
              "      <td>1.918529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>1.825400</td>\n",
              "      <td>1.917836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.920100</td>\n",
              "      <td>1.917209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>1.905800</td>\n",
              "      <td>1.916594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>1.946900</td>\n",
              "      <td>1.915945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>2.035800</td>\n",
              "      <td>1.915303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>1.883000</td>\n",
              "      <td>1.914687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>1.981600</td>\n",
              "      <td>1.913960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>1.960200</td>\n",
              "      <td>1.913222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>2.271800</td>\n",
              "      <td>1.912621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>1.821400</td>\n",
              "      <td>1.912059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>1.848300</td>\n",
              "      <td>1.911531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>2.183800</td>\n",
              "      <td>1.910988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>2.006400</td>\n",
              "      <td>1.910354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>2.118200</td>\n",
              "      <td>1.909738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>2.138200</td>\n",
              "      <td>1.909260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>1.986100</td>\n",
              "      <td>1.908753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>2.202200</td>\n",
              "      <td>1.908231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>2.051200</td>\n",
              "      <td>1.907679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>2.394200</td>\n",
              "      <td>1.907275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>2.027500</td>\n",
              "      <td>1.906901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>1.915700</td>\n",
              "      <td>1.906235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.927500</td>\n",
              "      <td>1.905764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>1.664500</td>\n",
              "      <td>1.905252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>1.817900</td>\n",
              "      <td>1.904768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>1.844700</td>\n",
              "      <td>1.904245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>1.813100</td>\n",
              "      <td>1.903681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>2.085900</td>\n",
              "      <td>1.903204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>2.106500</td>\n",
              "      <td>1.902668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>1.994900</td>\n",
              "      <td>1.902173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>1.848000</td>\n",
              "      <td>1.901657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>1.849700</td>\n",
              "      <td>1.901145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.966700</td>\n",
              "      <td>1.900674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>1.813800</td>\n",
              "      <td>1.900121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>1.942900</td>\n",
              "      <td>1.899499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>1.993900</td>\n",
              "      <td>1.899090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>2.087600</td>\n",
              "      <td>1.898481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>1.761500</td>\n",
              "      <td>1.898072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>1.882400</td>\n",
              "      <td>1.897532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>1.909300</td>\n",
              "      <td>1.897131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>1.758900</td>\n",
              "      <td>1.896788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>2.119900</td>\n",
              "      <td>1.896227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.850700</td>\n",
              "      <td>1.895773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>1.959100</td>\n",
              "      <td>1.895349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>1.898200</td>\n",
              "      <td>1.894918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>1.868300</td>\n",
              "      <td>1.894576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>1.950400</td>\n",
              "      <td>1.894156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>1.775200</td>\n",
              "      <td>1.893715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>1.797300</td>\n",
              "      <td>1.893310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>2.078500</td>\n",
              "      <td>1.892941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>2.035600</td>\n",
              "      <td>1.892461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>1.853600</td>\n",
              "      <td>1.892108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.878600</td>\n",
              "      <td>1.891682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>1.882400</td>\n",
              "      <td>1.891234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>1.963700</td>\n",
              "      <td>1.890760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>1.965500</td>\n",
              "      <td>1.890356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>2.343500</td>\n",
              "      <td>1.889962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>1.892800</td>\n",
              "      <td>1.889602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>1.805700</td>\n",
              "      <td>1.889255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>1.831900</td>\n",
              "      <td>1.888944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>2.065000</td>\n",
              "      <td>1.888624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>1.783900</td>\n",
              "      <td>1.888299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>2.012900</td>\n",
              "      <td>1.887922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>1.979100</td>\n",
              "      <td>1.887581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>1.890000</td>\n",
              "      <td>1.887272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>1.881600</td>\n",
              "      <td>1.886938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>1.815900</td>\n",
              "      <td>1.886621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.980400</td>\n",
              "      <td>1.886330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>1.976600</td>\n",
              "      <td>1.886027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>1.962600</td>\n",
              "      <td>1.885728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>1.997000</td>\n",
              "      <td>1.885407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>1.921100</td>\n",
              "      <td>1.885139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.892100</td>\n",
              "      <td>1.884838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>1.756000</td>\n",
              "      <td>1.884490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>2.177300</td>\n",
              "      <td>1.884200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>1.889500</td>\n",
              "      <td>1.883910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>2.033300</td>\n",
              "      <td>1.883629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>2.112300</td>\n",
              "      <td>1.883327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>1.777400</td>\n",
              "      <td>1.883040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>1.711900</td>\n",
              "      <td>1.882733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>1.835300</td>\n",
              "      <td>1.882438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>1.875300</td>\n",
              "      <td>1.882152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.779000</td>\n",
              "      <td>1.881892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>1.705200</td>\n",
              "      <td>1.881588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>1.786200</td>\n",
              "      <td>1.881280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>1.829600</td>\n",
              "      <td>1.880991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>1.899800</td>\n",
              "      <td>1.880749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>2.233500</td>\n",
              "      <td>1.880469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>2.169700</td>\n",
              "      <td>1.880203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>2.221300</td>\n",
              "      <td>1.879973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>2.032900</td>\n",
              "      <td>1.879714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>1.676000</td>\n",
              "      <td>1.879504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.817600</td>\n",
              "      <td>1.879254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>1.912200</td>\n",
              "      <td>1.879060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>1.811300</td>\n",
              "      <td>1.878855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>1.982600</td>\n",
              "      <td>1.878634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>2.236300</td>\n",
              "      <td>1.878417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>1.960300</td>\n",
              "      <td>1.878217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>1.890000</td>\n",
              "      <td>1.877990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>2.047700</td>\n",
              "      <td>1.877772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>1.673300</td>\n",
              "      <td>1.877528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>1.927900</td>\n",
              "      <td>1.877308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.733900</td>\n",
              "      <td>1.877053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>1.753700</td>\n",
              "      <td>1.876824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>2.043200</td>\n",
              "      <td>1.876624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>1.957100</td>\n",
              "      <td>1.876407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>1.901200</td>\n",
              "      <td>1.876207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>1.799500</td>\n",
              "      <td>1.875984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>1.890400</td>\n",
              "      <td>1.875821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>2.032200</td>\n",
              "      <td>1.875630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>2.049500</td>\n",
              "      <td>1.875457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>1.806100</td>\n",
              "      <td>1.875272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.896900</td>\n",
              "      <td>1.875111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>2.026500</td>\n",
              "      <td>1.874929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>1.918000</td>\n",
              "      <td>1.874785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>2.027300</td>\n",
              "      <td>1.874594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>1.985300</td>\n",
              "      <td>1.874417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>2.088900</td>\n",
              "      <td>1.874261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>2.190500</td>\n",
              "      <td>1.874095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>2.186500</td>\n",
              "      <td>1.873921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>1.958800</td>\n",
              "      <td>1.873772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>1.941500</td>\n",
              "      <td>1.873623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.786800</td>\n",
              "      <td>1.873455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>1.919500</td>\n",
              "      <td>1.873302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>1.743900</td>\n",
              "      <td>1.873137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>1.995600</td>\n",
              "      <td>1.872957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>1.959100</td>\n",
              "      <td>1.872820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>1.761600</td>\n",
              "      <td>1.872663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>1.983000</td>\n",
              "      <td>1.872487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>2.127700</td>\n",
              "      <td>1.872312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>2.029900</td>\n",
              "      <td>1.872161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>1.833100</td>\n",
              "      <td>1.871958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.855600</td>\n",
              "      <td>1.871784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>1.965900</td>\n",
              "      <td>1.871591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>2.028200</td>\n",
              "      <td>1.871449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>1.875000</td>\n",
              "      <td>1.871266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>2.151400</td>\n",
              "      <td>1.871137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>1.742100</td>\n",
              "      <td>1.870986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>1.911200</td>\n",
              "      <td>1.870832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>1.806900</td>\n",
              "      <td>1.870697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>1.651300</td>\n",
              "      <td>1.870565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>1.836600</td>\n",
              "      <td>1.870407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.920300</td>\n",
              "      <td>1.870273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>301</td>\n",
              "      <td>1.622500</td>\n",
              "      <td>1.870137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>302</td>\n",
              "      <td>1.851600</td>\n",
              "      <td>1.869975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>1.947700</td>\n",
              "      <td>1.869869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>304</td>\n",
              "      <td>2.096200</td>\n",
              "      <td>1.869737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>1.866300</td>\n",
              "      <td>1.869609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>1.972800</td>\n",
              "      <td>1.869481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>307</td>\n",
              "      <td>1.857000</td>\n",
              "      <td>1.869383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>308</td>\n",
              "      <td>2.070100</td>\n",
              "      <td>1.869264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>309</td>\n",
              "      <td>1.990800</td>\n",
              "      <td>1.869145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.862700</td>\n",
              "      <td>1.869021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>311</td>\n",
              "      <td>1.938000</td>\n",
              "      <td>1.868891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>2.084700</td>\n",
              "      <td>1.868789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>313</td>\n",
              "      <td>1.787200</td>\n",
              "      <td>1.868693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>314</td>\n",
              "      <td>1.790200</td>\n",
              "      <td>1.868537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>1.855000</td>\n",
              "      <td>1.868404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>316</td>\n",
              "      <td>2.209500</td>\n",
              "      <td>1.868317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>317</td>\n",
              "      <td>2.350500</td>\n",
              "      <td>1.868191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>318</td>\n",
              "      <td>1.954200</td>\n",
              "      <td>1.868090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>319</td>\n",
              "      <td>1.772500</td>\n",
              "      <td>1.867994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.782100</td>\n",
              "      <td>1.867893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>321</td>\n",
              "      <td>1.918300</td>\n",
              "      <td>1.867793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>322</td>\n",
              "      <td>1.715900</td>\n",
              "      <td>1.867700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>323</td>\n",
              "      <td>2.140100</td>\n",
              "      <td>1.867605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>1.785500</td>\n",
              "      <td>1.867452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>2.030600</td>\n",
              "      <td>1.867407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>326</td>\n",
              "      <td>1.897000</td>\n",
              "      <td>1.867314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>327</td>\n",
              "      <td>1.988900</td>\n",
              "      <td>1.867197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>328</td>\n",
              "      <td>2.212800</td>\n",
              "      <td>1.867161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>329</td>\n",
              "      <td>1.838300</td>\n",
              "      <td>1.867068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.961100</td>\n",
              "      <td>1.866957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>331</td>\n",
              "      <td>1.736600</td>\n",
              "      <td>1.866900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>332</td>\n",
              "      <td>1.837100</td>\n",
              "      <td>1.866832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>333</td>\n",
              "      <td>1.913800</td>\n",
              "      <td>1.866767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>334</td>\n",
              "      <td>2.033700</td>\n",
              "      <td>1.866675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>1.813500</td>\n",
              "      <td>1.866602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>2.051100</td>\n",
              "      <td>1.866530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>337</td>\n",
              "      <td>2.144100</td>\n",
              "      <td>1.866464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>338</td>\n",
              "      <td>1.956000</td>\n",
              "      <td>1.866374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>339</td>\n",
              "      <td>1.786800</td>\n",
              "      <td>1.866318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.950600</td>\n",
              "      <td>1.866233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>341</td>\n",
              "      <td>1.841000</td>\n",
              "      <td>1.866190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>342</td>\n",
              "      <td>1.801200</td>\n",
              "      <td>1.866094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>343</td>\n",
              "      <td>1.878900</td>\n",
              "      <td>1.866071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>344</td>\n",
              "      <td>1.799000</td>\n",
              "      <td>1.866000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>2.078700</td>\n",
              "      <td>1.865934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>346</td>\n",
              "      <td>2.047600</td>\n",
              "      <td>1.865857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>347</td>\n",
              "      <td>1.779400</td>\n",
              "      <td>1.865794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>348</td>\n",
              "      <td>1.945300</td>\n",
              "      <td>1.865727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>349</td>\n",
              "      <td>1.971400</td>\n",
              "      <td>1.865642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.876100</td>\n",
              "      <td>1.865624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>2.075600</td>\n",
              "      <td>1.865572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>352</td>\n",
              "      <td>1.729400</td>\n",
              "      <td>1.865519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>353</td>\n",
              "      <td>1.800700</td>\n",
              "      <td>1.865447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>354</td>\n",
              "      <td>1.816800</td>\n",
              "      <td>1.865388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>2.123000</td>\n",
              "      <td>1.865361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>356</td>\n",
              "      <td>1.990200</td>\n",
              "      <td>1.865344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>357</td>\n",
              "      <td>1.827600</td>\n",
              "      <td>1.865321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>358</td>\n",
              "      <td>1.698600</td>\n",
              "      <td>1.865267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>359</td>\n",
              "      <td>1.914600</td>\n",
              "      <td>1.865251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.660400</td>\n",
              "      <td>1.865217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>361</td>\n",
              "      <td>2.140000</td>\n",
              "      <td>1.865181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>362</td>\n",
              "      <td>1.959300</td>\n",
              "      <td>1.865142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>363</td>\n",
              "      <td>1.951500</td>\n",
              "      <td>1.865170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>364</td>\n",
              "      <td>2.419600</td>\n",
              "      <td>1.865078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>1.887800</td>\n",
              "      <td>1.865075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>366</td>\n",
              "      <td>1.655800</td>\n",
              "      <td>1.865030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>367</td>\n",
              "      <td>2.190900</td>\n",
              "      <td>1.865045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>368</td>\n",
              "      <td>1.909900</td>\n",
              "      <td>1.865029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>369</td>\n",
              "      <td>2.041700</td>\n",
              "      <td>1.864989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.691600</td>\n",
              "      <td>1.864987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>371</td>\n",
              "      <td>2.049200</td>\n",
              "      <td>1.864974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>1.832500</td>\n",
              "      <td>1.864973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>373</td>\n",
              "      <td>1.798400</td>\n",
              "      <td>1.864958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>374</td>\n",
              "      <td>1.771100</td>\n",
              "      <td>1.864956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.991100</td>\n",
              "      <td>1.864975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>376</td>\n",
              "      <td>1.849300</td>\n",
              "      <td>1.864968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 27\n",
            "  Batch size = 2\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37f8dc5bded449cf80df93432597d5a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>██▆▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▇▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▇▁▁</td></tr><tr><td>eval/samples_per_second</td><td>█████████████▂██▂██▂██████████████▁██▂██</td></tr><tr><td>eval/steps_per_second</td><td>█████████████▂██▂██▂██████████████▁██▂██</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>▆█▅▅▅▅▄▃▄▃▃▃▂▂▂▄▃▂▄▂▃▃▃▃▄▁▂▁▃▁▃▂▄▅▅▃▁▃▆▂</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.86497</td></tr><tr><td>eval/runtime</td><td>8.2202</td></tr><tr><td>eval/samples_per_second</td><td>3.285</td></tr><tr><td>eval/steps_per_second</td><td>1.703</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>376</td></tr><tr><td>train/grad_norm</td><td>0.27163</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.8493</td></tr><tr><td>train/total_flos</td><td>3.917057042782618e+16</td></tr><tr><td>train/train_loss</td><td>2.02059</td></tr><tr><td>train/train_runtime</td><td>6516.9247</td></tr><tr><td>train/train_samples_per_second</td><td>0.462</td></tr><tr><td>train/train_steps_per_second</td><td>0.058</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">run_10000</strong> at: <a href='https://wandb.ai/fengdu/tiny-llama/runs/0976sk6p' target=\"_blank\">https://wandb.ai/fengdu/tiny-llama/runs/0976sk6p</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240303_013417-0976sk6p/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\") # Local saving\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ],
      "metadata": {
        "id": "uCcxZ3LmcmKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52edf35e-1f62-4a80-c87a-95549d5f5ec5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--unsloth--tinyllama-bnb-4bit/snapshots/fc56510003ea9d49362400b8a362345150802c31/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"unsloth/tinyllama\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 5632,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 22,\n",
            "  \"num_key_value_heads\": 4,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.38.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('lora_model')"
      ],
      "metadata": {
        "id": "Xtm7VPssQh89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24e5ef03-47fc-4926-e8a5-86d98163d59c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab1604cc-33f3-4548-9f84-927b61105634\", \"lora_model\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/lora_model'\n",
        "model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "uY9MWGEDRwiI",
        "outputId": "13f82be5-2ea5-4584-fefb-141153e54d3b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LlamaForCausalLM' object has no attribute 'save'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PeftModelForCausalLM' object has no attribute 'save'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'save'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b2e9c41863a2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/lora_model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_peft_config_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LlamaForCausalLM' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Is the following an phishing attempt?\", # instruction\n",
        "        \"\"\"Subject: PayPal Payment Not Processed Successfully\n",
        "\n",
        "Personal Assistant Needed\n",
        "You are invited to participate in a Part-time work offer for current\n",
        "staff/students. For more information About the task CLICK HERE\n",
        "Application will be received and you will get a response between\n",
        "24- 48 hours.\n",
        "\n",
        "        \"\"\", # input\n",
        "        \"\", # output - leave this blank for a generation!\n",
        "    )\n",
        "]*1, return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O09n6I8zPqPm",
        "outputId": "9f0b8c5a-536a-4ef6-9f72-d9841bf5f6ca"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s> .\\n\\nGiven the input email and the reponse determine if the email provided below is safe or potentially malicious based on its\\ncontent. If the email seems legitimate and does not contain any\\nharmful intent, threats, or suspicious requests, classify it as\\n\"safe\". If the email contains elements typical of phishing attempts,\\nsuch as requests for sensitive information, suspicious links, or unusual\\nsender addresses, classify it as \"potentially malicious\".\\n\\n### Input:\\nIs the following an phishing attempt?\\n\\n### Response:\\nSubject: PayPal Payment Not Processed Successfully\\n\\nPersonal Assistant Needed\\nYou are invited to participate in a Part-time work offer for current\\nstaff/students. For more information About the task CLICK HERE\\nApplication will be received and you will get a response between\\n24- 48 hours.\\n\\n        \\n\\n\\n### Input:\\nSubject: Re: PayPal Payment Not Processed Successfully\\n\\nPersonal Assistant Needed\\nYou are invited to participate in a Part-time work offer for current\\nstaff/students. For more information About the task CLICK HERE\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6N_4BmjGZNPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}